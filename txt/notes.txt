adding more data
	multiple coins
		trade one vs multiple coins
	different coin types (normal, meme, etc)
	other than ohlcv data?
data
    add tickers
    should I include all data for pretraining, from spot to futures, from delisted coins, non usdt pairs, web3 over to different exchanges? and then finetune on the data, coins and exchange I will actually use? this would make the most sense
    should I also use a non broker source? but do they have volume? maybe they have other important data
evaluation
    1. prediction script
        actor(return_values=True)
    2. evaluation script
        trade with multiple coins
    performance to history length
    performance to future distance
    eval non trained coin
        never include
        include in training
        finetune on coin
        train and finetune
    trade for one week, gather all data, and check with offline data & performance (binance data vs bybit trading) (retrieve past trading data)    


evaluator
    dict = {}
    - key: symbol
    - value: timestamp, action values, reward, history (daata collector style)

    - i can calculate balance per symbol (is actually output of crypto_env)
    - i can analyse reward based on action values
    - i can come up with a multi coin trade strategy


actor
- get dictionary of symbols with current action = 0
- coins for multi trade are available as soon as action != 0


actor
    downloaded kline data
        try to use crypto_env functions
        offline trading
        reward history calculation
    function for choosing actions
        update history for chosen symbols
        use timestamps for robustness
    store trading performance
        check with training performance
        check with live performance
trader
    set to isolated, not cross
    store trading performance
        compare to offline performance
    how to do automatic periodic execution?
    main
        try initializing a few times
        before close all, retry, or reinitialize from beginning
        check for internet connection
            this would mean never halt entire program
    hierarchy: electricity (pc, program) -> internet (email) -> exchange public (market) -> exchange private (orders)
    when really want to stop: 
        closing all positions and sending email are asynchronous. (seperate servers)
        retry them until they work


crypto_env
    [train val, same reward function]
    [use initial balance as trading amount]
    [linear reward based on trading amount]
data_collector
    [implement importance sampling]
    [corrected rng]
learner & co
    [added batchnorm]
    [implement importance sampling]
main / training
    [add graceful shutdown]
    [check saving & loading]
    [orbax saving error]
    [jax complex warning]
bandits
    [added indeces saving and loading]
    [corrected rng]
metrics
    [use counter square root]
    [added metric state]
    [added cumulative reward]
    [split cumulative reward for greedy and stochastic policy]
    [add metric.add_infos]
    [log action lengths]
    [log action frequency]
    [log action rewards]
s5_rl
    add s5 rl implementation
huggingface
    how to finetune an llm?
    maybe ssm model
    a size that fits on my gpu


possible optimizations
    correct per init
        return q from actor
    retrace targets
    trade action reward function


runs
    lunarlander
    crypto
        if load_run, weight reset at beginning
        if load_model, new wandb run with loaded/resettet weights
        add tickers to create_observation
            maybe tickers.py
            what makes a ticker valuable?
        add more data
    metrics
        long, short


Bybit
commit message

changes:
- more efficient environment
- added constant investment option
- added linear rewards